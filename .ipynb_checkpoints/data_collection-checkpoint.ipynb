{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1aad3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from bs4 import MarkupResemblesLocatorWarning\n",
    "\n",
    "# Ignore MarkupResemblesLocatorWarning\n",
    "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7895e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_dict = {'Arizona Cardinals': 'ARI',\n",
    " 'Atlanta Falcons': 'ATL',\n",
    " 'Baltimore Colts': 'IND',\n",
    " 'Baltimore Ravens': 'BAL',\n",
    " 'Boston Patriots': 'NE',\n",
    " 'Buffalo Bills': 'BUF',\n",
    " 'Carolina Panthers': 'CAR',\n",
    " 'Chicago Bears': 'CHI',\n",
    " 'Cincinnati Bengals': 'CIN',\n",
    " 'Cleveland Browns': 'CLE',\n",
    " 'Dallas Cowboys': 'DAL',\n",
    " 'Denver Broncos': 'DEN',\n",
    " 'Detroit Lions': 'DET',\n",
    " 'Green Bay Packers': 'GB',\n",
    " 'Houston Oilers': 'TEN',\n",
    " 'Houston Texans': 'HOU',\n",
    " 'Indianapolis Colts': 'IND',\n",
    " 'Jacksonville Jaguars': 'JAX',\n",
    " 'Kansas City Chiefs': 'KC',\n",
    " 'Las Vegas Raiders': 'LVR',\n",
    " 'Los Angeles Chargers': 'LAC',\n",
    " 'Los Angeles Raiders': 'LVR',\n",
    " 'Los Angeles Rams': 'LAR',\n",
    " 'Miami Dolphins': 'MIA',\n",
    " 'Minnesota Vikings': 'MIN',\n",
    " 'New England Patriots': 'NE',\n",
    " 'New Orleans Saints': 'NO',\n",
    " 'New York Giants': 'NYG',\n",
    " 'New York Jets': 'NYJ',\n",
    " 'Oakland Raiders': 'LVR',\n",
    " 'Philadelphia Eagles': 'PHI',\n",
    " 'Phoenix Cardinals': 'ARI',\n",
    " 'Pittsburgh Steelers': 'PIT',\n",
    " 'San Diego Chargers': 'LAC',\n",
    " 'San Francisco 49ers': 'SF',\n",
    " 'Seattle Seahawks': 'SEA',\n",
    " 'St. Louis Cardinals': 'ARI',\n",
    " 'St. Louis Rams': 'LAR',\n",
    " 'Tampa Bay Buccaneers': 'TB',\n",
    " 'Tennessee Oilers': 'TEN',\n",
    " 'Tennessee Titans': 'TEN',\n",
    " 'Washington Commanders': 'WAS',\n",
    " 'Washington Football Team': 'WAS',\n",
    " 'Washington Redskins': 'WAS'}\n",
    "\n",
    "def format_week(week):\n",
    "    if week.isdigit():\n",
    "        return f\"Week{week}\"\n",
    "    return week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7de15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_game_context(season):\n",
    "    base_url = f\"https://www.pro-football-reference.com/years/{season}/games.htm\"\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching the season page: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    games_raw = soup.find_all('script', attrs={'type': 'application/ld+json'})\n",
    "    games_content = games_raw[0].string  \n",
    "    games_dict = json.loads(games_content)\n",
    "    game_names = [game['name'] for game in games_dict]\n",
    "    game_urls = [game['url'] for game in games_dict]\n",
    "\n",
    "    games_table = soup.find('table', id='games')\n",
    "    games_df = pd.read_html(str(games_table))[0]\n",
    "    games_df = games_df.loc[games_df['Week'] != 'Week']\n",
    "    games_df = games_df.dropna(subset=['Week'])\n",
    "    games_df['url'] = game_urls\n",
    "\n",
    "    aways = []\n",
    "    homes = []\n",
    "    for game in game_names:\n",
    "        away, home = game.split('@')\n",
    "        aways.append(team_dict[away[:-1]])\n",
    "        homes.append(team_dict[home[1:]])\n",
    "    games_df['Home'] = homes\n",
    "    games_df['Away'] = aways\n",
    "    games_df['Week'] = games_df['Week'].apply(format_week)\n",
    "    games_df['File'] = '' + str(season) + '_' + games_df['Week'] + '_' + games_df['Home'] + '_vs_' + games_df['Away']\n",
    "\n",
    "    return games_df\n",
    "\n",
    "def fetch_game_stats(game_url):\n",
    "    response = requests.get(game_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching the game page: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    all_tables = []\n",
    "    # Find tables not in comments\n",
    "    all_tables.extend(soup.find_all('table'))\n",
    "\n",
    "    # Find all comments and then find tables within those comments\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        comment_soup = BeautifulSoup(str(comment), 'html.parser')\n",
    "        tables_in_comment = comment_soup.find_all('table')\n",
    "        all_tables.extend(tables_in_comment)\n",
    "\n",
    "    game_data = {}\n",
    "    for table in all_tables:\n",
    "        table_id = table.get('id')\n",
    "        if table_id:\n",
    "            game_data[table_id] = (pd.read_html(str(table))[0])\n",
    "\n",
    "    return game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b82ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_season_stats(season, debug = False):\n",
    "    start_time = time.time()\n",
    "    df = fetch_game_context(season)\n",
    "\n",
    "    all_game_stats = {}\n",
    "    request_count = 0\n",
    "    \n",
    "    directory_path = os.path.join('raw_data', str(season))\n",
    "    file_path = os.path.join(directory_path, f\"{season}games.csv\")\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        game = df.iloc[i]\n",
    "        if request_count >= 19:\n",
    "            print(\"Reached 20 requests, sleeping for 60 seconds...\")\n",
    "            time.sleep(60)  # sleep for 60 seconds to respect the rate limit\n",
    "            request_count = 0\n",
    "        directory_path = os.path.join('raw_data', str(season), game['Week'], game['File'])\n",
    "        os.makedirs(directory_path, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            game_stats = fetch_game_stats(game['url'])\n",
    "        except:\n",
    "            print(\"Requests being limited, sleeping for 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "            request_count = 0\n",
    "            game_stats = fetch_game_stats(game['url'])\n",
    "        \n",
    "        if game_stats:\n",
    "            all_game_stats[game['File']] = game_stats\n",
    "            for key in game_stats.keys():\n",
    "                file_path = os.path.join(directory_path, f\"{key}.csv\")\n",
    "                game_stats[key].to_csv(file_path, index=False)\n",
    "            request_count += 1\n",
    "            if debug:\n",
    "                print(f\"Finished Processing {game['File']}...\")\n",
    "    \n",
    "    decimal_seconds = time.time() - start_time\n",
    "    whole_seconds = int(decimal_seconds)\n",
    "    fractional_seconds = decimal_seconds - whole_seconds\n",
    "    minutes = whole_seconds // 60 \n",
    "    seconds = whole_seconds % 60\n",
    "    seconds += fractional_seconds\n",
    "    formatted_time = f\"{minutes:02d}:{seconds:06.3f}\"\n",
    "    print(f'Completed Data Scraping of {season} NFL Season in {formatted_time} Seconds')\n",
    "    return df, all_game_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274275d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for season in range(2022, 2023):\n",
    "    _, _ = collect_season_stats(season, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334882b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
